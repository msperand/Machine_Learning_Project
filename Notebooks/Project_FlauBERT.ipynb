{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is the most advanced notebook having models of our project. It encompasses the techniques of data augmentation, through chat GPT and also through, a list of synonyms that we created (with the help of chat gpt)."
      ],
      "metadata": {
        "id": "64H37h7tKDfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the section of the Flaubert model, you can choose at the begining of the code what data you want to use as data_subset, so as training data.\n",
        "\n",
        "\n",
        "*   If you use training_data, you are using the generic data given on Kaggle.\n",
        "*   If you use output_data, you are using the generic and the synonym replacement done by chat gpt.\n",
        "*   If you are using output_data_final you are adding the paraphrasing on top.\n",
        "*   And finally, if you are using augmented_data then it is the Kaggle data and the manual replacement of synonyms with the list.\n",
        "Always make sure you have computed the corresponding section before doing that.\n",
        "\n"
      ],
      "metadata": {
        "id": "CL-RGXbsLVMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is set up initally to make the same predictions as we did in our best submissions with this method, so the 63.5% of the name \"DA_full_FlauBERT_large_vs0_2_bs16_decay0_05_rs42_dacs_1.csv\""
      ],
      "metadata": {
        "id": "GtEvk8eyNCBS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iANKWSO9KHiD"
      },
      "source": [
        "# Initialisation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FNH_1HCFXuWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d2e653f-cdd9-41dd-ce0c-cca69d6e1e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.11.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, sacremoses, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 multiprocess-0.70.16 sacremoses-0.1.1 xxhash-3.4.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.30.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!pip install datasets transformers huggingface_hub sacremoses\n",
        "!apt-get install git-lfs\n",
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U\n",
        "!pip install torch sklearn\n",
        "\n",
        "\n",
        "# Import required packages\n",
        "from transformers import pipeline, DataCollatorWithPadding\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from google.colab import files\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from google.colab import files\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.semi_supervised import SelfTrainingClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import xgboost as xgb\n",
        "import torchgen\n",
        "import string\n",
        "import nltk\n",
        "import torch\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvyPpHR0X6Mn",
        "outputId": "392d338f-6e5f-477b-dd03-8618e0de9f37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id difficulty\n",
            "0        0         A1\n",
            "1        1         A1\n",
            "2        2         A1\n",
            "3        3         A1\n",
            "4        4         A1\n",
            "...    ...        ...\n",
            "1195  1195         A1\n",
            "1196  1196         A1\n",
            "1197  1197         A1\n",
            "1198  1198         A1\n",
            "1199  1199         A1\n",
            "\n",
            "[1200 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# URL to the raw CSV file on GitHub\n",
        "url = 'https://raw.githubusercontent.com/msperand/Machine_Learning_Project/main/Data/sample_submission.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "sample_submission = pd.read_csv(url)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(sample_submission)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjkxtWLI486G",
        "outputId": "f13038c8-8e6c-4180-867d-27cec888eaf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id                                           sentence difficulty\n",
            "0        0  Les coûts kilométriques réels peuvent diverger...         C1\n",
            "1        1  Le bleu, c'est ma couleur préférée mais je n'a...         A1\n",
            "2        2  Le test de niveau en français est sur le site ...         A1\n",
            "3        3           Est-ce que ton mari est aussi de Boston?         A1\n",
            "4        4  Dans les écoles de commerce, dans les couloirs...         B1\n",
            "...    ...                                                ...        ...\n",
            "4795  4795  C'est pourquoi, il décida de remplacer les hab...         B2\n",
            "4796  4796  Il avait une de ces pâleurs splendides qui don...         C1\n",
            "4797  4797  Et le premier samedi de chaque mois, venez ren...         A2\n",
            "4798  4798  Les coûts liés à la journalisation n'étant pas...         C2\n",
            "4799  4799  Sur le sable, la mer haletait de toute la resp...         C2\n",
            "\n",
            "[4800 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# URL to the raw CSV file on GitHub\n",
        "url2 = 'https://raw.github.com/msperand/Machine_Learning_Project/main/Data/training_data.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "training_data = pd.read_csv(url2)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY4Prj815FOQ",
        "outputId": "77929632-efb6-4094-8e58-4ef4ca087973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id                                           sentence\n",
            "0        0  Nous dûmes nous excuser des propos que nous eû...\n",
            "1        1  Vous ne pouvez pas savoir le plaisir que j'ai ...\n",
            "2        2  Et, paradoxalement, boire froid n'est pas la b...\n",
            "3        3  Ce n'est pas étonnant, car c'est une saison my...\n",
            "4        4  Le corps de Golo lui-même, d'une essence aussi...\n",
            "...    ...                                                ...\n",
            "1195  1195  C'est un phénomène qui trouve une accélération...\n",
            "1196  1196  Je vais parler au serveur et voir si on peut d...\n",
            "1197  1197  Il n'était pas comme tant de gens qui par pare...\n",
            "1198  1198      Ils deviennent dangereux pour notre économie.\n",
            "1199  1199  Son succès a généré beaucoup de réactions néga...\n",
            "\n",
            "[1200 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# URL to the raw CSV file on GitHub\n",
        "url3 = 'https://raw.github.com/msperand/Machine_Learning_Project/main/Data/unlabelled_test_data.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "test_data = pd.read_csv(url3)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "uIHFGugrJX4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we upload and merge the datasets that we created using Chatgpt. One was done with synonym replacement , the other through paraphrasing. We end up with 14'400 sentences, many of which are duplicate, mostly because of teh low ability of chat gpt to find synonyms in French. However, this technique works very well, so we decided to keep it."
      ],
      "metadata": {
        "id": "krIFVWs_Jdzq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D5c9Ja_dOplW"
      },
      "outputs": [],
      "source": [
        "def merge_datasets(training_data, augmented_file, fraction):\n",
        "    \"\"\"\n",
        "    Merges a fraction of the augmented dataset with the existing training dataset.\n",
        "\n",
        "    Parameters:\n",
        "        training_data (pd.DataFrame): DataFrame containing the training data.\n",
        "        augmented_file (str): File path to the augmented dataset CSV.\n",
        "        fraction (float): Fraction of the augmented dataset to merge (between 0 and 1).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A new DataFrame containing the training data and the selected fraction of the augmented data.\n",
        "    \"\"\"\n",
        "    # Load the augmented dataset\n",
        "    augmented_data = pd.read_csv(augmented_file)\n",
        "\n",
        "    # Sample the fraction of the augmented data\n",
        "    sample_size = int(len(augmented_data) * fraction)\n",
        "    augmented_sample = augmented_data.sample(n=sample_size, random_state = 11)\n",
        "\n",
        "    # Concatenate the training data with the sampled augmented data\n",
        "    combined_data = pd.concat([training_data, augmented_sample], ignore_index=True)\n",
        "\n",
        "    return combined_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nmj38k1sCTSj",
        "outputId": "9c1c5423-15f6-402e-8b4b-10904e3f087c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                           sentence difficulty\n",
            "0   0  Les coûts kilométriques réels peuvent diverger...         C1\n",
            "1   1  Le bleu, c'est ma couleur préférée mais je n'a...         A1\n",
            "2   2  Le test de niveau en français est sur le site ...         A1\n",
            "3   3           Est-ce que ton mari est aussi de Boston?         A1\n",
            "4   4  Dans les écoles de commerce, dans les couloirs...         B1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Example usage assuming 'training_data' is already a DataFrame:\n",
        "# training_data = pd.read_csv('training_data.csv')  # Assuming this step is done elsewhere in your code\n",
        "\n",
        "augmented_file_path = 'https://raw.githubusercontent.com/msperand/Machine_Learning_Project/main/Data/augmented_training_data_chat_synonym.csv'  # Specify the path to your augmented dataset\n",
        "output_data = merge_datasets(training_data, augmented_file_path, 1)\n",
        "print(output_data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m0BKt1yywak",
        "outputId": "b33c864e-1939-41ac-8cc1-c028e56998ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                           sentence difficulty\n",
            "0   0  Les coûts kilométriques réels peuvent diverger...         C1\n",
            "1   1  Le bleu, c'est ma couleur préférée mais je n'a...         A1\n",
            "2   2  Le test de niveau en français est sur le site ...         A1\n",
            "3   3           Est-ce que ton mari est aussi de Boston?         A1\n",
            "4   4  Dans les écoles de commerce, dans les couloirs...         B1\n"
          ]
        }
      ],
      "source": [
        "augmented_file_path_2 = 'https://raw.githubusercontent.com/msperand/Machine_Learning_Project/main/Data/enhanced_paraphrased_data.csv'  # Specify the path to your augmented dataset\n",
        "output_data_final = merge_datasets(output_data, augmented_file_path_2, 1)\n",
        "print(output_data_final.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh_yBdA2I7nY",
        "outputId": "8ccd6b89-4e7f-4281-9ba1-30857e3b739b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14400, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "output_data_final.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation with a list of synonym"
      ],
      "metadata": {
        "id": "QjOqAILuLQYw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwCngDMiY9F4"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# Extensive list of words with their difficulty levels\n",
        "corpus = [\n",
        "    (\"chat\", \"A1\"), (\"chien\", \"A1\"), (\"maison\", \"A2\"), (\"voiture\", \"A2\"), (\"ordinateur\", \"B1\"),\n",
        "    (\"programme\", \"B1\"), (\"difficulté\", \"C1\"), (\"intelligence\", \"C1\"), (\"livre\", \"A1\"), (\"école\", \"A1\"),\n",
        "    (\"pomme\", \"A1\"), (\"banane\", \"A1\"), (\"avion\", \"A2\"), (\"bicyclette\", \"A2\"), (\"université\", \"B1\"),\n",
        "    (\"recherche\", \"B1\"), (\"philosophie\", \"C1\"), (\"mathématique\", \"C1\"), (\"musique\", \"A1\"), (\"film\", \"A1\"),\n",
        "    (\"étoile\", \"A1\"), (\"lune\", \"A1\"), (\"soleil\", \"A2\"), (\"planète\", \"A2\"), (\"galaxie\", \"B1\"),\n",
        "    (\"univers\", \"B1\"), (\"théorie\", \"C1\"), (\"science\", \"C1\"), (\"mer\", \"A1\"), (\"océan\", \"A1\"),\n",
        "    (\"rivière\", \"A2\"), (\"lac\", \"A2\"), (\"montagne\", \"B1\"), (\"vallée\", \"B1\"), (\"désert\", \"C1\"),\n",
        "    (\"forêt\", \"C1\"), (\"arbre\", \"A1\"), (\"fleur\", \"A1\"), (\"herbe\", \"A1\"), (\"jardin\", \"A1\"),\n",
        "    (\"oiseau\", \"A1\"), (\"chaton\", \"A1\"), (\"chiot\", \"A1\"), (\"poisson\", \"A1\"), (\"tigre\", \"B1\"),\n",
        "    (\"lion\", \"B1\"), (\"serpent\", \"B1\"), (\"éléphant\", \"B1\"), (\"girafe\", \"B1\"), (\"zèbre\", \"B1\"),\n",
        "    (\"rhinocéros\", \"C1\"), (\"hippopotame\", \"C1\"), (\"panthère\", \"C1\"), (\"léopard\", \"C1\"),\n",
        "    (\"maître\", \"A1\"), (\"étudiant\", \"A1\"), (\"professeur\", \"A2\"), (\"docteur\", \"A2\"), (\"ingénieur\", \"B1\"),\n",
        "    (\"scientifique\", \"B1\"), (\"astronaute\", \"C1\"), (\"pompier\", \"C1\"), (\"policier\", \"A1\"),\n",
        "    (\"infirmier\", \"A1\"), (\"boulanger\", \"A1\"), (\"boucher\", \"A2\"), (\"cuisinier\", \"A2\"),\n",
        "    (\"serveur\", \"A2\"), (\"écrivain\", \"B1\"), (\"poète\", \"B1\"), (\"artiste\", \"B1\"), (\"musicien\", \"B1\"),\n",
        "    (\"acteur\", \"B1\"), (\"chanteur\", \"B1\"), (\"danseur\", \"B1\"), (\"peintre\", \"C1\"), (\"sculpteur\", \"C1\"),\n",
        "    (\"architecte\", \"C1\"), (\"photographe\", \"C1\"), (\"cinéaste\", \"C1\"), (\"vérité\", \"A1\"),\n",
        "    (\"amitié\", \"A1\"), (\"amour\", \"A1\"), (\"joie\", \"A1\"), (\"tristesse\", \"A2\"), (\"colère\", \"A2\"),\n",
        "    (\"peur\", \"A2\"), (\"courage\", \"B1\"), (\"espoir\", \"B1\"), (\"désespoir\", \"B1\"), (\"liberté\", \"B1\"),\n",
        "    (\"égalité\", \"C1\"), (\"fraternité\", \"C1\"), (\"justice\", \"C1\"), (\"paix\", \"C1\"), (\"bâtiment\", \"A1\"),\n",
        "    (\"vêtements\", \"A1\"), (\"chaussures\", \"A1\"), (\"téléphone\", \"A2\"), (\"ordinateur\", \"A2\"),\n",
        "    (\"table\", \"A1\"), (\"chaise\", \"A1\"), (\"lit\", \"A1\"), (\"fenêtre\", \"A2\"), (\"porte\", \"A2\"),\n",
        "    (\"toit\", \"B1\"), (\"mur\", \"B1\"), (\"sol\", \"B1\"), (\"plafond\", \"B1\"), (\"cuisine\", \"B1\"),\n",
        "    (\"salle\", \"B1\"), (\"salon\", \"B1\"), (\"chambre\", \"B1\"), (\"bureau\", \"B1\"), (\"garage\", \"B1\"),\n",
        "    (\"jardin\", \"B1\"), (\"balcon\", \"C1\"), (\"terrasse\", \"C1\"), (\"cheminée\", \"C1\"), (\"toiture\", \"C1\"),\n",
        "    (\"sous-sol\", \"C1\"), (\"grenier\", \"C1\"), (\"escalier\", \"C1\"), (\"ascenseur\", \"C1\"), (\"couloir\", \"C1\"),\n",
        "    (\"télévision\", \"A1\"), (\"radio\", \"A1\"), (\"livre\", \"A1\"), (\"magazine\", \"A1\"), (\"journal\", \"A1\"),\n",
        "    (\"ordinateur\", \"A1\"), (\"téléphone\", \"A1\"), (\"smartphone\", \"A2\"), (\"tablette\", \"A2\"),\n",
        "    (\"écran\", \"A2\"), (\"clavier\", \"A2\"), (\"souris\", \"A2\"), (\"imprimante\", \"A2\"), (\"scanner\", \"B1\"),\n",
        "    (\"copieur\", \"B1\"), (\"modem\", \"B1\"), (\"routeur\", \"B1\"), (\"wifi\", \"B1\"), (\"internet\", \"B1\"),\n",
        "    (\"courriel\", \"B1\"), (\"email\", \"B1\"), (\"site\", \"B1\"), (\"page\", \"B1\"), (\"web\", \"B1\"),\n",
        "    (\"blog\", \"B1\"), (\"forum\", \"B1\"), (\"chat\", \"B1\"), (\"réseau\", \"B1\"), (\"social\", \"B1\"),\n",
        "    (\"média\", \"B1\"), (\"application\", \"B1\"), (\"logiciel\", \"B1\"), (\"programme\", \"B1\"), (\"système\", \"B1\")\n",
        "]\n",
        "\n",
        "# Manually defined synonyms for the extensive list of words\n",
        "synonyms = {\n",
        "    \"chat\": [\"félin\", \"minou\"],\n",
        "    \"chien\": [\"canidé\", \"toutou\"],\n",
        "    \"maison\": [\"demeure\", \"habitation\"],\n",
        "    \"voiture\": [\"automobile\", \"véhicule\"],\n",
        "    \"ordinateur\": [\"PC\", \"machine\"],\n",
        "    \"programme\": [\"logiciel\", \"application\"],\n",
        "    \"difficulté\": [\"complexité\", \"obstacle\"],\n",
        "    \"intelligence\": [\"cognition\", \"sagacité\"],\n",
        "    \"livre\": [\"ouvrage\", \"bouquin\"],\n",
        "    \"école\": [\"établissement\", \"institution\"],\n",
        "    \"pomme\": [\"fruit\", \"pommette\"],\n",
        "    \"banane\": [\"fruit\", \"plantain\"],\n",
        "    \"avion\": [\"aéronef\", \"appareil\"],\n",
        "    \"bicyclette\": [\"vélo\", \"cycle\"],\n",
        "    \"université\": [\"faculté\", \"institution\"],\n",
        "    \"recherche\": [\"investigation\", \"exploration\"],\n",
        "    \"philosophie\": [\"pensée\", \"sagesse\"],\n",
        "    \"mathématique\": [\"calcul\", \"arithmétique\"],\n",
        "    \"musique\": [\"mélodie\", \"harmonie\"],\n",
        "    \"film\": [\"cinéma\", \"pellicule\"],\n",
        "    \"étoile\": [\"astre\", \"lueur\"],\n",
        "    \"lune\": [\"satellite\", \"astre\"],\n",
        "    \"soleil\": [\"astre\", \"étoile\"],\n",
        "    \"planète\": [\"astre\", \"globe\"],\n",
        "    \"galaxie\": [\"constellation\", \"nébuleuse\"],\n",
        "    \"univers\": [\"cosmos\", \"infini\"],\n",
        "    \"théorie\": [\"hypothèse\", \"concept\"],\n",
        "    \"science\": [\"savoir\", \"connaissance\"],\n",
        "    \"mer\": [\"océan\", \"étendue\"],\n",
        "    \"océan\": [\"mer\", \"étendue\"],\n",
        "    \"rivière\": [\"fleuve\", \"cours d'eau\"],\n",
        "    \"lac\": [\"étang\", \"plan d'eau\"],\n",
        "    \"montagne\": [\"sommet\", \"pic\"],\n",
        "    \"vallée\": [\"dépression\", \"creux\"],\n",
        "    \"désert\": [\"étendue\", \"aridité\"],\n",
        "    \"forêt\": [\"bois\", \"jungle\"],\n",
        "    \"arbre\": [\"plante\", \"végétal\"],\n",
        "    \"fleur\": [\"floral\", \"bloom\"],\n",
        "    \"herbe\": [\"gazon\", \"pelouse\"],\n",
        "    \"jardin\": [\"parc\", \"terrain\"],\n",
        "    \"oiseau\": [\"volatile\", \"piaf\"],\n",
        "    \"chaton\": [\"minou\", \"félin\"],\n",
        "    \"chiot\": [\"toutou\", \"canidé\"],\n",
        "    \"poisson\": [\"poiscaille\", \"poiscaille\"],\n",
        "    \"tigre\": [\"félin\", \"panthère\"],\n",
        "    \"lion\": [\"roi des animaux\", \"félin\"],\n",
        "    \"serpent\": [\"ophidien\", \"reptile\"],\n",
        "    \"éléphant\": [\"pachyderme\", \"géant\"],\n",
        "    \"girafe\": [\"cervidé\", \"animal\"],\n",
        "    \"zèbre\": [\"animal\", \"rayé\"],\n",
        "    \"rhinocéros\": [\"pachyderme\", \"animal\"],\n",
        "    \"hippopotame\": [\"pachyderme\", \"animal\"],\n",
        "    \"panthère\": [\"félin\", \"tigre\"],\n",
        "    \"léopard\": [\"félin\", \"panthère\"],\n",
        "    \"maître\": [\"professeur\", \"enseignant\"],\n",
        "    \"étudiant\": [\"élève\", \"apprenant\"],\n",
        "    \"professeur\": [\"enseignant\", \"instructeur\"],\n",
        "    \"docteur\": [\"médecin\", \"praticien\"],\n",
        "    \"ingénieur\": [\"technicien\", \"spécialiste\"],\n",
        "    \"scientifique\": [\"chercheur\", \"érudit\"],\n",
        "    \"astronaute\": [\"cosmonaute\", \"explorateur\"],\n",
        "    \"pompier\": [\"sapeur\", \"secouriste\"],\n",
        "    \"policier\": [\"gendarme\", \"agent\"],\n",
        "    \"infirmier\": [\"soignant\", \"assistant médical\"],\n",
        "    \"boulanger\": [\"pâtissier\", \"artisan\"],\n",
        "    \"boucher\": [\"charcutier\", \"viandard\"],\n",
        "    \"cuisinier\": [\"chef\", \"cordon-bleu\"],\n",
        "    \"serveur\": [\"garçon\", \"commis\"],\n",
        "    \"écrivain\": [\"auteur\", \"littérateur\"],\n",
        "    \"poète\": [\"versificateur\", \"rimeur\"],\n",
        "    \"artiste\": [\"créateur\", \"peintre\"],\n",
        "    \"musicien\": [\"instrumentiste\", \"compositeur\"],\n",
        "    \"acteur\": [\"comédien\", \"artiste\"],\n",
        "    \"chanteur\": [\"vocaliste\", \"interprète\"],\n",
        "    \"danseur\": [\"balletomane\", \"chorégraphe\"],\n",
        "    \"peintre\": [\"plasticien\", \"artiste\"],\n",
        "    \"sculpteur\": [\"modeleur\", \"statuaire\"],\n",
        "    \"architecte\": [\"concepteur\", \"designer\"],\n",
        "    \"photographe\": [\"cameraman\", \"documentariste\"],\n",
        "    \"cinéaste\": [\"réalisateur\", \"metteur en scène\"],\n",
        "    \"vérité\": [\"réalité\", \"exactitude\"],\n",
        "    \"amitié\": [\"camaraderie\", \"compagnonnage\"],\n",
        "    \"amour\": [\"affection\", \"tendresse\"],\n",
        "    \"joie\": [\"bonheur\", \"contentement\"],\n",
        "    \"tristesse\": [\"chagrin\", \"désolation\"],\n",
        "    \"colère\": [\"fureur\", \"irritation\"],\n",
        "    \"peur\": [\"crainte\", \"terreur\"],\n",
        "    \"courage\": [\"bravoure\", \"audace\"],\n",
        "    \"espoir\": [\"espérance\", \"optimisme\"],\n",
        "    \"désespoir\": [\"désolation\", \"découragement\"],\n",
        "    \"liberté\": [\"indépendance\", \"autonomie\"],\n",
        "    \"égalité\": [\"équité\", \"justice\"],\n",
        "    \"fraternité\": [\"solidarité\", \"camaraderie\"],\n",
        "    \"justice\": [\"équité\", \"impartialité\"],\n",
        "    \"paix\": [\"tranquillité\", \"harmonie\"],\n",
        "    \"bâtiment\": [\"édifice\", \"construction\"],\n",
        "    \"vêtements\": [\"habits\", \"tenues\"],\n",
        "    \"chaussures\": [\"souliers\", \"godasses\"],\n",
        "    \"téléphone\": [\"portable\", \"mobile\"],\n",
        "    \"table\": [\"meuble\", \"bureau\"],\n",
        "    \"chaise\": [\"siège\", \"tabouret\"],\n",
        "    \"lit\": [\"couche\", \"sommeil\"],\n",
        "    \"fenêtre\": [\"ouverture\", \"baie\"],\n",
        "    \"porte\": [\"entrée\", \"issue\"],\n",
        "    \"toit\": [\"couvrement\", \"abri\"],\n",
        "    \"mur\": [\"paroi\", \"cloison\"],\n",
        "    \"sol\": [\"terre\", \"terrain\"],\n",
        "    \"plafond\": [\"ciel\", \"voute\"],\n",
        "    \"cuisine\": [\"gastronomie\", \"culinaire\"],\n",
        "    \"salle\": [\"pièce\", \"chambre\"],\n",
        "    \"salon\": [\"séjour\", \"living\"],\n",
        "    \"bureau\": [\"travail\", \"étude\"],\n",
        "    \"garage\": [\"stationnement\", \"atelier\"],\n",
        "    \"balcon\": [\"terrasse\", \"loggia\"],\n",
        "    \"terrasse\": [\"balcon\", \"patio\"],\n",
        "    \"cheminée\": [\"foyer\", \"âtre\"],\n",
        "    \"toiture\": [\"couvrement\", \"toit\"],\n",
        "    \"sous-sol\": [\"cave\", \"entresol\"],\n",
        "    \"grenier\": [\"combles\", \"mezzanine\"],\n",
        "    \"escalier\": [\"marches\", \"degré\"],\n",
        "    \"ascenseur\": [\"élévateur\", \"monte-charge\"],\n",
        "    \"couloir\": [\"corridor\", \"passage\"],\n",
        "    \"télévision\": [\"TV\", \"télé\"],\n",
        "    \"radio\": [\"TSF\", \"émetteur\"],\n",
        "    \"magazine\": [\"revue\", \"périodique\"],\n",
        "    \"journal\": [\"quotidien\", \"gazette\"],\n",
        "    \"smartphone\": [\"téléphone intelligent\", \"mobile\"],\n",
        "    \"tablette\": [\"PC\", \"ardoise\"],\n",
        "    \"écran\": [\"moniteur\", \"affichage\"],\n",
        "    \"clavier\": [\"pianotage\", \"dactylo\"],\n",
        "    \"souris\": [\"mulot\", \"pointeur\"],\n",
        "    \"imprimante\": [\"copieur\", \"machine à imprimer\"],\n",
        "    \"scanner\": [\"numériseur\", \"lecteur\"],\n",
        "    \"copieur\": [\"duplicateur\", \"reprographie\"],\n",
        "    \"modem\": [\"routeur\", \"connecteur\"],\n",
        "    \"routeur\": [\"commutateur\", \"connecteur\"],\n",
        "    \"wifi\": [\"réseau sans fil\", \"connexion\"],\n",
        "    \"internet\": [\"cyberspace\", \"toile\"],\n",
        "    \"courriel\": [\"email\", \"message électronique\"],\n",
        "    \"email\": [\"courriel\", \"message électronique\"],\n",
        "    \"site\": [\"web\", \"page\"],\n",
        "    \"page\": [\"site\", \"feuille\"],\n",
        "    \"web\": [\"internet\", \"site\"],\n",
        "    \"blog\": [\"journal en ligne\", \"site personnel\"],\n",
        "    \"forum\": [\"discussion\", \"groupe\"],\n",
        "    \"chat\": [\"discussion en ligne\", \"conversation\"],\n",
        "    \"réseau\": [\"network\", \"connexion\"],\n",
        "    \"social\": [\"réseautage\", \"interaction\"],\n",
        "    \"média\": [\"médium\", \"communication\"],\n",
        "    \"application\": [\"logiciel\", \"programme\"],\n",
        "    \"logiciel\": [\"programme\", \"application\"],\n",
        "    \"programme\": [\"logiciel\", \"application\"],\n",
        "    \"système\": [\"réseau\", \"infrastructure\"]\n",
        "}\n",
        "\n",
        "# Create a dictionary for synonyms with the same difficulty\n",
        "synonym_dict = defaultdict(list)\n",
        "for word, difficulty in corpus:\n",
        "    for synonym in synonyms.get(word, []):\n",
        "        synonym_dict[word].append((synonym, difficulty))\n",
        "\n",
        "# Function for synonym replacement\n",
        "def synonym_replacement(sentence, synonym_dict, n):\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "    random_word_list = list(set([word for word in words if word in synonym_dict]))\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "        synonyms = [syn for syn, _ in synonym_dict[random_word]]\n",
        "        if len(synonyms) >= 1:\n",
        "            synonym = random.choice(synonyms)\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:\n",
        "            break\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "# Function to augment an entire dataset\n",
        "def augment_dataset(data, synonym_dict, augmentations_per_sentence=1):\n",
        "    augmented_data = data.copy()\n",
        "    for _ in range(augmentations_per_sentence):\n",
        "        augmented_sentences = [\n",
        "            synonym_replacement(sentence, synonym_dict, 1) for sentence in data['sentence']\n",
        "        ]\n",
        "        augmented_subset = data.copy()\n",
        "        augmented_subset['sentence'] = augmented_sentences\n",
        "        augmented_data = pd.concat([augmented_data, augmented_subset])\n",
        "    augmented_data.reset_index(drop=True, inplace=True)\n",
        "    return augmented_data\n",
        "\n",
        "# Augment the dataset\n",
        "augmented_data = augment_dataset(training_data, synonym_dict, augmentations_per_sentence=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vkNhkoieaQip",
        "outputId": "65ac98e6-225d-42ac-b386-2194eac2dd14"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"augmented_data\",\n  \"rows\": 14400,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1385,\n        \"min\": 0,\n        \"max\": 4799,\n        \"num_unique_values\": 4800,\n        \"samples\": [\n          596,\n          3370,\n          3048\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5759,\n        \"samples\": [\n          \"Je resterai, n\\u00e9anmoins, fid\\u00e8le \\u00e0 ma r\\u00e8gle habituelle, qui consiste \\u00e0 accorder la pr\\u00e9f\\u00e9rence aux affaires dont l'int\\u00e9r\\u00eat provient moins de la sauvagerie du crime que de l'ing\\u00e9niosit\\u00e9 et de l'impr\\u00e9vu de la solution.\",\n          \"Cet auteur tellement lu pour sa Grammaire impertinente propose aussi des Jeux pour lire vite.\",\n          \"Je t'\\u00e9cris de France, o\\u00f9 je vis avec ma famille depuis deux mois\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"difficulty\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"C1\",\n          \"A1\",\n          \"C2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "augmented_data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a9848355-2196-4f19-bd59-a8d9103d1911\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Le test de niveau en français est sur le site ...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14395</th>\n",
              "      <td>4795</td>\n",
              "      <td>C'est pourquoi, il décida de remplacer les hab...</td>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14396</th>\n",
              "      <td>4796</td>\n",
              "      <td>Il avait une de ces pâleurs splendides qui don...</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14397</th>\n",
              "      <td>4797</td>\n",
              "      <td>Et le premier samedi de chaque mois, venez ren...</td>\n",
              "      <td>A2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14398</th>\n",
              "      <td>4798</td>\n",
              "      <td>Les coûts liés à la journalisation n'étant pas...</td>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14399</th>\n",
              "      <td>4799</td>\n",
              "      <td>Sur le sable, la étendue haletait de toute la ...</td>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14400 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9848355-2196-4f19-bd59-a8d9103d1911')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a9848355-2196-4f19-bd59-a8d9103d1911 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a9848355-2196-4f19-bd59-a8d9103d1911');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bfd2b555-9a5e-46e0-a7d3-3523c06ac1bf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bfd2b555-9a5e-46e0-a7d3-3523c06ac1bf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bfd2b555-9a5e-46e0-a7d3-3523c06ac1bf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         id                                           sentence difficulty\n",
              "0         0  Les coûts kilométriques réels peuvent diverger...         C1\n",
              "1         1  Le bleu, c'est ma couleur préférée mais je n'a...         A1\n",
              "2         2  Le test de niveau en français est sur le site ...         A1\n",
              "3         3           Est-ce que ton mari est aussi de Boston?         A1\n",
              "4         4  Dans les écoles de commerce, dans les couloirs...         B1\n",
              "...     ...                                                ...        ...\n",
              "14395  4795  C'est pourquoi, il décida de remplacer les hab...         B2\n",
              "14396  4796  Il avait une de ces pâleurs splendides qui don...         C1\n",
              "14397  4797  Et le premier samedi de chaque mois, venez ren...         A2\n",
              "14398  4798  Les coûts liés à la journalisation n'étant pas...         C2\n",
              "14399  4799  Sur le sable, la étendue haletait de toute la ...         C2\n",
              "\n",
              "[14400 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "augmented_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FlauBERT-large-cased"
      ],
      "metadata": {
        "id": "1-JtInaWK5V9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1523044966454648a53a2063023f0e05",
            "679f45151790432aa4278b6cb8334ddb",
            "a4ddd5269f30437ab2f39c4ec138df33",
            "4af59d83a37d42d7a754dc23d4bae915",
            "b0391393d812434fb24084a89c1ec40d",
            "7bfe815dabf24724937fa3f31c9b37ac",
            "a51ea87cd9ef4371b6fd46e793c771e2",
            "b1b7fa4977d1414f8bf0ebb79bd4cb84",
            "22294a3a071d4abc9a3845a0231e801b",
            "d26abd2260dc40e19e973979bc5e50dd",
            "55c206f10af44fb4ba9b6abd84a7d8f4",
            "25e1457a118942119bbbf5582c4ee523",
            "55c22df1a73d42f09bca7c1a305937cb",
            "800eba77298147d69de8945355b52a56",
            "a308303f7dab4f858e75a66c6095d105",
            "367e0ab0a6bb497d94c70c08b9bbca4e",
            "0b35c11179544fcd8d51e625fcf6e31c",
            "402bc0f3b70e4518bb9d9a28ea40ac26",
            "aa723af694ee44d09cf557d982d59e9c",
            "fad149ff610a4c6fad4d601d50d133a6",
            "560de7327bbc4f4aba6bfd4a892de5d5",
            "842077deec264f56a96ca46c106c86d6",
            "3535a8528db346e99ede63bee516b003",
            "1f1fbf42b7b14e5d99b352e91b56a3d0",
            "3b890c78fcb546bf9154a4d687c5eaff",
            "c53a45fee9f64570bbfa1243d5635dd2",
            "96e76a0456084b389c775d7ad297013b",
            "dd207da33c944793b984d818e4418821",
            "94274c5b76564d2abb2a0bd054ee41a6",
            "a396c25307f34f3f91bda9588e725741",
            "99d68a80a16a406ab427a062bd24a168",
            "5737939dc0834729b01608d03fec3cee",
            "7f10b84a6aab4f59ae9cda89a8de0df0",
            "a0a4977b743842189574333580fa3ab0",
            "a6b5b96c5cd749dbba0159af1afe2ecd",
            "b94a98c7aa5a4126bd12efb9148d4fb5",
            "b0a14e81466b44f6a4be06997c73de98",
            "baf9eac8b55743f1a464babb8cb32da0",
            "ee115ff5bded46f096d9bae098f39cc0",
            "c8339a0005f74e80a402340665b66c78",
            "392f0c86231640a1a02e2cafea89b7cc",
            "d6d93740a40a44ef9844f0453f758113",
            "27b9cb8a69404440a5eeb0de60edb826",
            "5d2d4202f7f5452a91a88967d20eb35a",
            "789fdd6584364da0af435c6d1603c4bf",
            "17dcc085d6f54445903a4e8c17feedfc",
            "fb40bd2e4ec04791adf520d2d3e10cc2",
            "3fdd036b399b4901bb630c7d76f47983",
            "7a32a4b9841b4862b57a666e70a5707b",
            "66a934f574934827af7dff64b62936d7",
            "667e23c9b15445f5b23aa5ded4a32a6a",
            "e2aa2189564942adaf36deee4de98503",
            "dca1ab4ecc7040e99d4f7e2a1d52cf5b",
            "174c343b10f042159a8ddf4e4af01766",
            "c73cf4d7f32743bbb5106b7ae3d3db9f"
          ]
        },
        "id": "EfC-oiabTKUd",
        "outputId": "f6a12ae5-6638-405a-9e5a-b211dce51fac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1523044966454648a53a2063023f0e05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25e1457a118942119bbbf5582c4ee523",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.56M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3535a8528db346e99ede63bee516b003",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/896k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0a4977b743842189574333580fa3ab0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "789fdd6584364da0af435c6d1603c4bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.49G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-f2083f2e9aaa>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3600' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3600/3600 21:28, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.171000</td>\n",
              "      <td>1.034055</td>\n",
              "      <td>0.577431</td>\n",
              "      <td>0.617856</td>\n",
              "      <td>0.577431</td>\n",
              "      <td>0.576000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.826300</td>\n",
              "      <td>0.608880</td>\n",
              "      <td>0.773264</td>\n",
              "      <td>0.789014</td>\n",
              "      <td>0.773264</td>\n",
              "      <td>0.774372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.343900</td>\n",
              "      <td>0.293873</td>\n",
              "      <td>0.909722</td>\n",
              "      <td>0.910142</td>\n",
              "      <td>0.909722</td>\n",
              "      <td>0.909715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.189400</td>\n",
              "      <td>0.227209</td>\n",
              "      <td>0.957292</td>\n",
              "      <td>0.957685</td>\n",
              "      <td>0.957292</td>\n",
              "      <td>0.957183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.138800</td>\n",
              "      <td>0.198051</td>\n",
              "      <td>0.971875</td>\n",
              "      <td>0.972041</td>\n",
              "      <td>0.971875</td>\n",
              "      <td>0.971885</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-f2083f2e9aaa>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-f2083f2e9aaa>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-f2083f2e9aaa>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-f2083f2e9aaa>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-f2083f2e9aaa>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-f2083f2e9aaa>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-f2083f2e9aaa>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-f2083f2e9aaa>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-f2083f2e9aaa>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-f2083f2e9aaa>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "<ipython-input-9-f2083f2e9aaa>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3600, training_loss=0.6788036198996835, metrics={'train_runtime': 1289.9946, 'train_samples_per_second': 44.651, 'train_steps_per_second': 2.791, 'total_flos': 1.33735620575232e+16, 'train_loss': 0.6788036198996835, 'epoch': 5.0})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, get_scheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import FlaubertModel, FlaubertTokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import FlaubertTokenizer, FlaubertForSequenceClassification\n",
        "\n",
        "\n",
        "# Assuming the data is loaded into DataFrame 'training_data'\n",
        "#data_subset = training_data\n",
        "#data_subset = output_data\n",
        "data_subset = output_data_final\n",
        "#data_subset = augmented_data\n",
        "\n",
        "# Split the subset into training and validation sets\n",
        "train_data, val_data = train_test_split(data_subset, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set a random seed for PyTorch\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels = label_encoder.fit_transform(train_data['difficulty'])\n",
        "val_labels = label_encoder.transform(val_data['difficulty'])\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = FlaubertTokenizer.from_pretrained('flaubert/flaubert_large_cased')\n",
        "model = FlaubertForSequenceClassification.from_pretrained('flaubert/flaubert_large_cased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# Function to tokenize the data\n",
        "def tokenize_function(texts):\n",
        "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "# Tokenize the data\n",
        "train_encodings = tokenize_function(train_data['sentence'].tolist())\n",
        "val_encodings = tokenize_function(val_data['sentence'].tolist())\n",
        "\n",
        "# Prepare datasets\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = Dataset(train_encodings, train_labels)\n",
        "val_dataset = Dataset(val_encodings, val_labels)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "# Switching from 'bert-base-multilingual-cased' to 'bert-large-multilingual-cased'\n",
        "tokenizer = FlaubertTokenizer.from_pretrained('flaubert/flaubert_large_cased')\n",
        "model = FlaubertForSequenceClassification.from_pretrained('flaubert/flaubert_large_cased', num_labels=len(label_encoder.classes_))\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "# Training arguments: Increasing the number of training epochs\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,  # 5 in baseline\n",
        "    per_device_train_batch_size=16, #8 in baseline\n",
        "    per_device_eval_batch_size=16, #16 in Baseline\n",
        "    warmup_steps=500, # 500 in baseline\n",
        "    weight_decay=0.05, # 0.01 in baseline\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "\n",
        "# Trainer setup with a custom optimizer and scheduler\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics  # Define a function to compute metrics if needed\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "A53ehU0XT2SX",
        "outputId": "f0688c65-18ea-4181-99d0-419b8c2ac688"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-f920a3d36839>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_20641595-2b61-4edc-9e6a-550809723143\", \"DA_full_FlauBERT_large_vs0_2_decay0_05_rs42_dacs_1_download.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Assuming the model and tokenizer are already loaded\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "#model = BertForSequenceClassification.from_pretrained('./model_directory', num_labels=len(label_encoder.classes_))\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Load the test data (assuming it's loaded into a DataFrame named test_data)\n",
        "# test_data = pd.read_csv('path/to/your/test_data.csv')  # Uncomment if you need to load from a file\n",
        "\n",
        "# Tokenize the test data\n",
        "def tokenize_data(texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "test_encodings = tokenize_data(test_data['sentence'].tolist())\n",
        "\n",
        "\n",
        "# Create a DataLoader for the test data\n",
        "class TestData(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "test_dataset = TestData(test_encodings)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Predicting with the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=-1)\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "# Convert numerical predictions back to labels\n",
        "predicted_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "# Create DataFrame with IDs and predicted difficulties\n",
        "submission_df = pd.DataFrame({'id': test_data['id'], 'difficulty': predicted_labels})\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "submission_file_path = 'DA_full_FlauBERT_large_vs0_2_decay0_05_rs42_dacs_1.csv' #dacs = data audmentation chat synonym, full = dacs and paraphrasing\n",
        "submission_df.to_csv(submission_file_path, index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8Wa9OLJ8BOL",
        "outputId": "fbb7e7f1-e0b9-4146-f62f-ff77472f690a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./DA_full_FlauBERT_large_vs0_2_decay0_05_rs42_dacs_1_tokenizer/tokenizer_config.json',\n",
              " './DA_full_FlauBERT_large_vs0_2_decay0_05_rs42_dacs_1_tokenizer/special_tokens_map.json',\n",
              " './DA_full_FlauBERT_large_vs0_2_decay0_05_rs42_dacs_1_tokenizer/vocab.json',\n",
              " './DA_full_FlauBERT_large_vs0_2_decay0_05_rs42_dacs_1_tokenizer/merges.txt',\n",
              " './DA_full_FlauBERT_large_vs0_2_decay0_05_rs42_dacs_1_tokenizer/added_tokens.json')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the model\n",
        "model.save_pretrained('./DA_full_FlauBERT_large_vs0_2_decay0_05_rs42_dacs_1_model')\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained('./DA_full_FlauBERT_large_vs0_2_decay0_05_rs42_dacs_1_tokenizer')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths to save the model and tokenizer\n",
        "drive_model_path = '/content/drive/My Drive/DA_full_FlauBERT_large_vs0_2_decay0_05_rs42_dacs_1_model'\n",
        "drive_tokenizer_path = '/content/drive/My Drive/DA_full_FlauBERT_large_vs0_2_decay0_05_rs42_dacs_1_tokenizer'\n",
        "\n",
        "# Save the model to Google Drive\n",
        "model.save_pretrained(drive_model_path)\n",
        "\n",
        "# Save the tokenizer to Google Drive\n",
        "tokenizer.save_pretrained(drive_tokenizer_path)\n",
        "\n",
        "# Zip the model directory\n",
        "shutil.make_archive(drive_model_path, 'zip', drive_model_path)\n",
        "\n",
        "# Zip the tokenizer directory\n",
        "shutil.make_archive(drive_tokenizer_path, 'zip', drive_tokenizer_path)\n",
        "\n",
        "print(f\"Model and tokenizer saved to Google Drive. You can download them from your Google Drive at:\")\n",
        "print(f\"Model path: {drive_model_path}.zip\")\n",
        "print(f\"Tokenizer path: {drive_tokenizer_path}.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqLBv3Nzs5dx",
        "outputId": "fa5acbe2-abe7-4779-9ddb-0c4ca96d922f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model and tokenizer saved to Google Drive. You can download them from your Google Drive at:\n",
            "Model path: /content/drive/My Drive/DA_full_FlauBERT_large_vs0_2_decay0_05_rs42_dacs_1_model.zip\n",
            "Tokenizer path: /content/drive/My Drive/DA_full_FlauBERT_large_vs0_2_decay0_05_rs42_dacs_1_tokenizer.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part allows us to download the model and tokenizer on our google drive. It is the only way we manage to store it, as we did not manage to put it on GitHub."
      ],
      "metadata": {
        "id": "xEQEabkuNjTc"
      }
    }
  ]
}